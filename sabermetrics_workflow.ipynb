{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from airflow import models\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "\n",
    "default_dag_args = {\n",
    "    # https://airflow.apache.org/faq.html#what-s-the-deal-with-start-date\n",
    "    'start_date': datetime.datetime(2019, 12, 06)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_dataset = 'sabermetrics_workflow_staging'\n",
    "modeled_dataset = 'sabermetrics_workflow_modeled'\n",
    "\n",
    "bq_query_start = 'bq query --use_legacy_sql=false '\n",
    "\n",
    "create_jBat_sql =  'create or replace table ' + modeled_dataset + '''.jBat as\n",
    "                    select distinct row_number() over (partition BY Year) as index, Year, City, Team, TeamID, LName, FName, \n",
    "                    safe_cast(Avg as FLOAT64) as Avg, safe_cast(SLG as FLOAT64) as SLG, \n",
    "                    safe_cast(OBP as FLOAT64) as OBP, safe_cast(RiSP as FLOAT64) as RiSP, \n",
    "                    G, AB, R, H, _2B, _3B, HR, RBI, BB, HBP, SO, SB, GIDP, safe_cast(PA as INT64) as PA, \n",
    "                    Sac, E, PlayerID, Uniform, safe_cast(ARISP as FLOAT64) as ARISP, \n",
    "                    safe_cast(SF as INT64) as SF, safe_cast(SH as INT64) as SH, \n",
    "                    safe_cast(DP as INT64) as DP, Bats, LG, Throws, safe_cast(RC_27 as FLOAT64) as RC_27, \n",
    "                    safe_cast(A as INT64) as A, safe_cast(Pos1 as INT64) as Pos1, Pos,  \n",
    "                    safe_cast(D_G as INT64) as D_G , safe_cast( PO as INT64) as PO , \n",
    "                    safe_cast(CS as INT64) as CS, \"dummy\" as playerpk from ''' + staging_dataset + '.jBatters order by Year' \n",
    "\n",
    "update_jBat_sql1 = 'UPDATE ' + modeled_dataset + '''.jBat\n",
    "                    SET playerpk = concat(cast(LName as string), cast(FName as string), cast(Team as string), cast(Year as string), cast(index as string))\n",
    "                    WHERE FName is not null ''' \n",
    "\n",
    "update_jBat_sql2 = 'UPDATE ' + modeled_dataset + '''.jBat\n",
    "                    SET playerpk = concat(cast(LName as string), cast(Team as string), cast(Year as string), cast(index as string))\n",
    "                    WHERE FName is null ''' \n",
    "\n",
    "update_jBat_sql3 = 'UPDATE ' + modeled_dataset + '''.jBat\n",
    "                    SET playerpk = concat(cast(FName as string), cast(Team as string), cast(Year as string), cast(index as string))\n",
    "                    WHERE LName is null '''\n",
    "\n",
    "\n",
    "\n",
    "with models.DAG(\n",
    "        'sabermetrics_workflow',\n",
    "        schedule_interval=None,\n",
    "        default_args=default_dag_args) as dag:\n",
    "\n",
    "    create_staging_dataset = BashOperator(\n",
    "            task_id='create_staging_dataset',\n",
    "            bash_command='bq --location=US mk --dataset ' + staging_dataset)\n",
    "    \n",
    "    create_modeled_dataset = BashOperator(\n",
    "            task_id='create_modeled_dataset',\n",
    "            bash_command='bq --location=US mk --dataset ' + modeled_dataset)\n",
    "    \n",
    "    load_npbb = BashOperator(\n",
    "            task_id='load_npbb',\n",
    "            bash_command='bq --location=US load --autodetect --skip_leading_rows=1 \\\n",
    "                         --source_format=CSV ' + staging_dataset + '.jBatters \\\n",
    "                         \"gs://sabermetrics_bucket_ajn873/raw/npbb.csv\"',\n",
    "            trigger_rule='one_success')\n",
    "   \n",
    "    split = DummyOperator(\n",
    "            task_id='split',\n",
    "            trigger_rule='all_done')\n",
    "\n",
    "    split_jBat = DummyOperator(\n",
    "            task_id='split_student',\n",
    "            trigger_rule='all_done')\n",
    "    \n",
    "    create_jBat = BashOperator(\n",
    "            task_id='create_jBat',\n",
    "            bash_command=bq_query_start + \"'\" + create_jBat_sql + \"'\", \n",
    "            trigger_rule='one_success')\n",
    "    \n",
    "    update_jBat1 = BashOperator(\n",
    "            task_id='update_jBat1',\n",
    "            bash_command=bq_query_start + \"'\" + update_jBat_sql1 + \"'\", \n",
    "            trigger_rule='one_success')\n",
    "    update_jBat2 = BashOperator(\n",
    "            task_id='update_jBat2',\n",
    "            bash_command=bq_query_start + \"'\" + update_jBat_sql2 + \"'\", \n",
    "            trigger_rule='one_success')\n",
    "    update_jBat3 = BashOperator(\n",
    "            task_id='update_jBat3',\n",
    "            bash_command=bq_query_start + \"'\" + update_jBat_sql3 + \"'\", \n",
    "            trigger_rule='one_success')\n",
    "    \n",
    "    jBat_beam = BashOperator(\n",
    "            task_id='jBat_beam',\n",
    "            bash_command='python/home/jupyter/airflow/dags/jBat_single.py')\n",
    "    \n",
    "    #jBat_dataflow = BashOperator(\n",
    "    #        task_id='jBat_dataflow',\n",
    "    #        bash_command='python/home/jupyter/airflow/dags/jBat_cluster.py')\n",
    "        \n",
    " \n",
    "    \n",
    "    create_staging_dataset >> create_modeled_dataset >> split\n",
    "    split >> load_npbb >> create_jBat >> update_jBat1 >> update_jBat2 >> update_jBat3 >> split_jBat\n",
    "    split_jBat >> jBat_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
